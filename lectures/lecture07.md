### Lecture: 7. Recurrent Neural Networks
#### Date: Apr 14

- Sequence modelling using Recurrent Neural Networks (RNN) [Chapter 10 until Section 10.2.1 (excluding) of DLB]
- Bidirectional RNN [Section 10.3 of DLB]
- The challenge of long-term dependencies [Section 10.7 of DLB]
- Long Short-Term Memory (LSTM) [Section 10.10.1 of DLB, *[Sepp Hochreiter, Jürgen Schmidhuber (1997): Long short-term memory](http://www.bioinf.jku.at/publications/older/2604.pdf), [felix A. Gers, Jürgen Schmidhuber, Fred Cummins (2000): Learning to Forget: Continual Prediction with LSTM](ftp://ftp.idsia.ch/pub/juergen/FgGates-NC.pdf)*]
- Gated Recurrent Unit (GRU) [Section 10.10.2 of DLB, *[Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio: Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078)*]
- Highway Networks [[Rupesh Kumar Srivastava, Klaus Greff, Jürgen Schmidhuber: **Training Very Deep Networks**](https://arxiv.org/abs/1507.06228)]
- RNN Regularization
  - Variational Dropout [[Yarin Gal, Zoubin Ghahramani: **A Theoretically Grounded Application of Dropout in Recurrent Neural Networks**](https://arxiv.org/abs/1512.05287)]
  - Layer Normalization [[Jimmy Lei Ba, Jamie Ryan Kiros, Geoffrey E. Hinton: **Layer Normalization**](https://arxiv.org/abs/1607.06450)]
